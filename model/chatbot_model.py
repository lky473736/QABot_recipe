"""
ìˆ˜ì •ëœ ë ˆì‹œí”¼ ì±—ë´‡ ëª¨ë¸ í´ë˜ìŠ¤ - ë°ì´í„° ë¡œë”© ë¬¸ì œ í•´ê²°
"""
import json
import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
from typing import List, Dict, Any, Tuple
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import *
from utils.text_preprocessor import TextPreprocessor

class RecipeChatbot:
    """ë ˆì‹œí”¼ ì±—ë´‡ í´ë˜ìŠ¤ - ë°ì´í„° ë¡œë”© ë¬¸ì œ í•´ê²°"""
    
    def __init__(self, model_path=None):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.tokenizer = None
        self.model = None
        self.text_processor = TextPreprocessor()
        
        print(f"ğŸ”§ ì±—ë´‡ ì´ˆê¸°í™” ì¤‘...")
        
        # ë°ì´í„° ë¡œë“œ (ì˜¬ë°”ë¥¸ íŒŒì¼ë“¤ ë¡œë“œ)
        self.recipes = self.load_recipes()
        self.qa_dataset = self.load_qa_dataset()
        
        print(f"ğŸ“Š ë¡œë“œëœ ë ˆì‹œí”¼ ìˆ˜: {len(self.recipes)}")
        print(f"ğŸ“Š ë¡œë“œëœ QA ìˆ˜: {len(self.qa_dataset)}")
        
        # ë°ì´í„°ê°€ ì ìœ¼ë©´ ê²½ê³ 
        if len(self.recipes) < 100:
            print(f"âš ï¸ ë ˆì‹œí”¼ê°€ {len(self.recipes)}ê°œë°–ì— ì—†ìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        if len(self.qa_dataset) < 100:
            print(f"âš ï¸ QAê°€ {len(self.qa_dataset)}ê°œë°–ì— ì—†ìŠµë‹ˆë‹¤. ë” ë§ì€ QA ë°ì´í„°ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ëª¨ë¸ ë¡œë“œ
        if model_path and os.path.exists(model_path):
            self.load_model(model_path)
        else:
            # ì‚¬ì „ í›ˆë ¨ëœ KcBERT ì‚¬ìš©
            self.load_pretrained_model()
    
    def load_recipes(self) -> List[Dict[str, Any]]:
        """ë ˆì‹œí”¼ ë°ì´í„° ë¡œë“œ - ì˜¬ë°”ë¥¸ êµ¬ì¡° ì²˜ë¦¬"""
        try:
            if PROCESSED_RECIPES_PATH.exists():
                print(f"ğŸ“‚ ë ˆì‹œí”¼ íŒŒì¼ ë¡œë”©: {PROCESSED_RECIPES_PATH}")
                with open(PROCESSED_RECIPES_PATH, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ë°ì´í„° êµ¬ì¡° ë¶„ì„
                recipes = []
                
                if isinstance(data, dict):
                    if 'metadata' in data and 'recipes' in data:
                        # ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” êµ¬ì¡°
                        recipes = data['recipes']
                        print(f"âœ… ë©”íƒ€ë°ì´í„° êµ¬ì¡°ì—ì„œ ë ˆì‹œí”¼ ë¡œë“œ")
                        print(f"ğŸ“ˆ ë©”íƒ€ë°ì´í„°: {data['metadata']}")
                    elif 'recipes' in data:
                        recipes = data['recipes']
                    else:
                        # ë‹¤ë¥¸ í‚¤ì—ì„œ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°
                        for key, value in data.items():
                            if isinstance(value, list) and len(value) > 0:
                                if isinstance(value[0], dict) and 'name' in value[0]:
                                    recipes = value
                                    print(f"âœ… '{key}' í‚¤ì—ì„œ ë ˆì‹œí”¼ ë¡œë“œ")
                                    break
                elif isinstance(data, list):
                    recipes = data
                
                # ìœ íš¨í•œ ë ˆì‹œí”¼ë§Œ í•„í„°ë§
                valid_recipes = []
                for recipe in recipes:
                    if isinstance(recipe, dict) and recipe.get('name'):
                        valid_recipes.append(recipe)
                
                print(f"ğŸ“Š ìœ íš¨í•œ ë ˆì‹œí”¼: {len(valid_recipes)}ê°œ")
                return valid_recipes
            else:
                print(f"âŒ ë ˆì‹œí”¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {PROCESSED_RECIPES_PATH}")
                return []
                
        except Exception as e:
            print(f"âŒ ë ˆì‹œí”¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def load_qa_dataset(self) -> List[Dict[str, Any]]:
        """QA ë°ì´í„°ì…‹ ë¡œë“œ - ì˜¬ë°”ë¥¸ êµ¬ì¡° ì²˜ë¦¬"""
        try:
            if QA_DATASET_PATH.exists():
                print(f"ğŸ“‚ QA íŒŒì¼ ë¡œë”©: {QA_DATASET_PATH}")
                with open(QA_DATASET_PATH, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ë°ì´í„° êµ¬ì¡° ë¶„ì„
                qa_pairs = []
                
                if isinstance(data, dict):
                    if 'metadata' in data and 'qa_pairs' in data:
                        # ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” êµ¬ì¡°
                        qa_pairs = data['qa_pairs']
                        print(f"âœ… ë©”íƒ€ë°ì´í„° êµ¬ì¡°ì—ì„œ QA ë¡œë“œ")
                        print(f"ğŸ“ˆ ë©”íƒ€ë°ì´í„°: {data['metadata']}")
                    elif 'qa_pairs' in data:
                        qa_pairs = data['qa_pairs']
                    else:
                        # ë‹¤ë¥¸ í‚¤ì—ì„œ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°
                        for key, value in data.items():
                            if isinstance(value, list) and len(value) > 0:
                                if isinstance(value[0], dict) and 'question' in value[0]:
                                    qa_pairs = value
                                    print(f"âœ… '{key}' í‚¤ì—ì„œ QA ë¡œë“œ")
                                    break
                elif isinstance(data, list):
                    qa_pairs = data
                
                # ìœ íš¨í•œ QAë§Œ í•„í„°ë§
                valid_qa = []
                for qa in qa_pairs:
                    if isinstance(qa, dict) and qa.get('question') and qa.get('answer'):
                        valid_qa.append(qa)
                
                print(f"ğŸ“Š ìœ íš¨í•œ QA: {len(valid_qa)}ê°œ")
                return valid_qa
            else:
                print(f"âŒ QA íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {QA_DATASET_PATH}")
                return []
                
        except Exception as e:
            print(f"âŒ QA ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def load_pretrained_model(self):
        """ì‚¬ì „ í›ˆë ¨ëœ KcBERT ëª¨ë¸ ë¡œë“œ"""
        print("ì‚¬ì „ í›ˆë ¨ëœ KcBERT ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
            self.model = AutoModel.from_pretrained(MODEL_NAME)
            self.model.to(self.device)
            self.model.eval()
            self.text_processor.load_tokenizer(MODEL_NAME)
            print("âœ… KcBERT ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ KcBERT ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def load_model(self, model_path: str):
        """í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ"""
        print(f"í›ˆë ¨ëœ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤: {model_path}")
        
        try:
            # ì„¤ì • ë¡œë“œ
            config_path = os.path.join(model_path, "config.json")
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                print(f"ğŸ“‹ ëª¨ë¸ ì„¤ì •: {config}")
            else:
                print("âš ï¸ config.jsonì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì • ì‚¬ìš©.")
                config = {'model_name': MODEL_NAME}
            
            # í† í¬ë‚˜ì´ì € ë¡œë“œ
            tokenizer_path = os.path.join(model_path, "tokenizer")
            if os.path.exists(tokenizer_path):
                self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)
                print("âœ… ì»¤ìŠ¤í…€ í† í¬ë‚˜ì´ì € ë¡œë“œ")
            else:
                self.tokenizer = AutoTokenizer.from_pretrained(config.get('model_name', MODEL_NAME))
                print("âœ… ê¸°ë³¸ í† í¬ë‚˜ì´ì € ë¡œë“œ")
            
            # ëª¨ë¸ ë¡œë“œ
            self.model = AutoModel.from_pretrained(config.get('model_name', MODEL_NAME))
            
            # í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
            model_file = os.path.join(model_path, "pytorch_model.bin")
            if os.path.exists(model_file):
                print("ğŸ“¦ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘...")
                state_dict = torch.load(model_file, map_location=self.device)
                
                # ëª¨ë¸ êµ¬ì¡°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ strict=False ì‚¬ìš©
                missing_keys, unexpected_keys = self.model.load_state_dict(state_dict, strict=False)
                
                if missing_keys:
                    print(f"âš ï¸ ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ")
                if unexpected_keys:
                    print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected_keys)}ê°œ")
                
                print("âœ… í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
            else:
                print("âš ï¸ pytorch_model.binì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©.")
            
            self.model.to(self.device)
            self.model.eval()
            self.text_processor.load_tokenizer(tokenizer_path if os.path.exists(tokenizer_path) else config.get('model_name', MODEL_NAME))
            
            print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ”„ ê¸°ë³¸ KcBERTë¡œ í´ë°±")
            self.load_pretrained_model()
    
    def encode_text(self, text: str) -> np.ndarray:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ì¸ì½”ë”©"""
        if not self.tokenizer or not self.model:
            raise ValueError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            clean_text = self.text_processor.clean_text(text)
            
            # í† í¬ë‚˜ì´ì§• (ê¸¸ì´ ì œí•œ)
            inputs = self.tokenizer(
                clean_text,
                add_special_tokens=True,
                max_length=300,  # KcBERT ì°¨ì›ì— ë§ì¶¤
                padding='max_length',
                truncation=True,
                return_tensors='pt'
            )
            
            # GPUë¡œ ì´ë™
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ì¸ì½”ë”©
            with torch.no_grad():
                outputs = self.model(**inputs)
                
                # ì•ˆì „í•œ ì„ë² ë”© ì¶”ì¶œ
                if hasattr(outputs, 'pooler_output') and outputs.pooler_output is not None:
                    embeddings = outputs.pooler_output.cpu().numpy()
                else:
                    # [CLS] í† í° ì‚¬ìš©
                    embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
            
            return embeddings
            
        except Exception as e:
            print(f"âš ï¸ í…ìŠ¤íŠ¸ ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            # ë”ë¯¸ ì„ë² ë”© ë°˜í™˜
            return np.zeros((1, 300))
    
    def find_similar_qa(self, question: str, top_k: int = 5) -> List[Tuple[Dict[str, Any], float]]:
        """ìœ ì‚¬í•œ QA ì°¾ê¸°"""
        if not self.qa_dataset:
            print("âš ï¸ QA ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            # ì§ˆë¬¸ ì¸ì½”ë”©
            question_embedding = self.encode_text(question)
            
            # ëª¨ë“  QAì˜ ì§ˆë¬¸ ì¸ì½”ë”©
            qa_embeddings = []
            valid_qa = []
            
            for qa in self.qa_dataset[:100]:  # ì„±ëŠ¥ì„ ìœ„í•´ ì²˜ìŒ 100ê°œë§Œ ì‚¬ìš©
                try:
                    qa_embedding = self.encode_text(qa['question'])
                    qa_embeddings.append(qa_embedding)
                    valid_qa.append(qa)
                except:
                    continue
            
            if not qa_embeddings:
                print("âš ï¸ ìœ íš¨í•œ QA ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            qa_embeddings = np.vstack(qa_embeddings)
            similarities = cosine_similarity(question_embedding, qa_embeddings)[0]
            
            # ìƒìœ„ kê°œ ì„ íƒ
            top_indices = np.argsort(similarities)[::-1][:top_k]
            
            results = []
            for idx in top_indices:
                similarity = similarities[idx]
                if similarity > 0.3:  # ì„ê³„ê°’
                    results.append((valid_qa[idx], similarity))
            
            return results
            
        except Exception as e:
            print(f"âš ï¸ ìœ ì‚¬ QA ì°¾ê¸° ì‹¤íŒ¨: {e}")
            return []
    
    def search_recipes_by_ingredient(self, ingredient: str) -> List[Dict[str, Any]]:
        """ì¬ë£Œë¡œ ë ˆì‹œí”¼ ê²€ìƒ‰"""
        matching_recipes = []
        
        for recipe in self.recipes:
            ingredients_text = recipe.get('ingredients', '')
            if ingredient in ingredients_text:
                matching_recipes.append(recipe)
        
        return matching_recipes[:5]
    
    def search_recipes_by_name(self, name: str) -> List[Dict[str, Any]]:
        """ì´ë¦„ìœ¼ë¡œ ë ˆì‹œí”¼ ê²€ìƒ‰"""
        matching_recipes = []
        
        for recipe in self.recipes:
            recipe_name = recipe.get('name', '')
            if name in recipe_name:
                matching_recipes.append(recipe)
        
        return matching_recipes[:3]
    
    def get_recipe_by_id(self, recipe_id: str) -> Dict[str, Any]:
        """IDë¡œ ë ˆì‹œí”¼ ì°¾ê¸°"""
        for recipe in self.recipes:
            if recipe.get('id') == recipe_id:
                return recipe
        return {}
    
    def format_recipe_response(self, recipe: Dict[str, Any], response_type: str = 'full') -> str:
        """ë ˆì‹œí”¼ ì‘ë‹µ í¬ë§·íŒ…"""
        if not recipe:
            return "í•´ë‹¹ ë ˆì‹œí”¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        name = recipe.get('name', 'ì•Œ ìˆ˜ ì—†ëŠ” ìš”ë¦¬')
        
        if response_type == 'ingredients':
            ingredients = recipe.get('ingredients', 'ì¬ë£Œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')
            return f"{name}ì˜ ì¬ë£Œ:\n{ingredients}"
        
        elif response_type == 'steps':
            steps = recipe.get('steps', [])
            if steps:
                steps_text = []
                for i, step in enumerate(steps[:10], 1):
                    steps_text.append(f"{i}. {step}")
                return f"{name} ë§Œë“œëŠ” ë°©ë²•:\n\n" + "\n".join(steps_text)
            else:
                return f"{name}ì˜ ì¡°ë¦¬ë²• ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        elif response_type == 'nutrition':
            nutrition_info = []
            if recipe.get('calories'):
                nutrition_info.append(f"ì¹¼ë¡œë¦¬: {recipe['calories']}kcal")
            if recipe.get('carbs'):
                nutrition_info.append(f"íƒ„ìˆ˜í™”ë¬¼: {recipe['carbs']}g")
            if recipe.get('protein'):
                nutrition_info.append(f"ë‹¨ë°±ì§ˆ: {recipe['protein']}g")
            if recipe.get('fat'):
                nutrition_info.append(f"ì§€ë°©: {recipe['fat']}g")
            if recipe.get('sodium'):
                nutrition_info.append(f"ë‚˜íŠ¸ë¥¨: {recipe['sodium']}mg")
            
            if nutrition_info:
                return f"{name}ì˜ ì˜ì–‘ì •ë³´:\n" + "\n".join(nutrition_info)
            else:
                return f"{name}ì˜ ì˜ì–‘ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        else:  # full
            response = f"ğŸ³ {name}\n\n"
            
            if recipe.get('ingredients'):
                response += f"ğŸ“‹ ì¬ë£Œ:\n{recipe['ingredients']}\n\n"
            
            steps = recipe.get('steps', [])
            if steps:
                response += "ğŸ‘¨â€ğŸ³ ì¡°ë¦¬ë²•:\n"
                for i, step in enumerate(steps[:5], 1):
                    response += f"{i}. {step}\n"
                if len(steps) > 5:
                    response += f"... (ì´ {len(steps)}ë‹¨ê³„)\n"
                response += "\n"
            
            nutrition_info = []
            if recipe.get('calories'):
                nutrition_info.append(f"ì¹¼ë¡œë¦¬: {recipe['calories']}kcal")
            if nutrition_info:
                response += f"ğŸ“Š ì˜ì–‘ì •ë³´: {', '.join(nutrition_info)}\n"
            
            return response.strip()
    
    def classify_question_intent(self, question: str) -> str:
        """ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜"""
        question_lower = question.lower()
        
        if any(word in question for word in ['ì¬ë£Œ', 'ë­ê°€ ë“¤ì–´ê°€', 'í•„ìš”í•œ ì¬ë£Œ']):
            return 'ingredients'
        elif any(word in question for word in ['ë§Œë“¤', 'ì¡°ë¦¬', 'ì–´ë–»ê²Œ', 'ë°©ë²•', 'ë ˆì‹œí”¼']):
            return 'steps'
        elif any(word in question for word in ['ì¹¼ë¡œë¦¬', 'ì˜ì–‘', 'ì—´ëŸ‰']):
            return 'nutrition'
        elif any(word in question for word in ['íŒ', 'ë¹„ë²•', 'ì£¼ì˜ì‚¬í•­']):
            return 'tips'
        elif any(word in question for word in ['ì¶”ì²œ', 'ë­', 'ë¬´ì—‡', 'ìš”ë¦¬']):
            return 'recommendation'
        else:
            return 'general'
    
    def generate_response(self, user_input: str) -> str:
        """ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±"""
        if not user_input.strip():
            return "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ë ˆì‹œí”¼ë‚˜ ìš”ë¦¬ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!"
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        clean_input = self.text_processor.normalize_question(user_input)
        
        # ì¸ì‚¬ë§ ì²˜ë¦¬
        if any(greeting in clean_input for greeting in ['ì•ˆë…•', 'í—¬ë¡œ', 'í•˜ì´']):
            return "ì•ˆë…•í•˜ì„¸ìš”! ë ˆì‹œí”¼ ì±—ë´‡ì…ë‹ˆë‹¤. ìš”ë¦¬ ë ˆì‹œí”¼ë‚˜ ì¬ë£Œì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ³"
        
        # ë„ì›€ë§ ì²˜ë¦¬
        if any(help_word in clean_input for help_word in ['ë„ì›€', 'ë„ì™€ì¤˜', 'ë­ í•´ì¤„ ìˆ˜ ìˆì–´']):
            return f"""ë ˆì‹œí”¼ ì±—ë´‡ì´ ë„ì™€ë“œë¦´ ìˆ˜ ìˆëŠ” ê²ƒë“¤:

ğŸ” ì¬ë£Œë¡œ ìš”ë¦¬ ê²€ìƒ‰: "ê°ìë¡œ ë­ ë§Œë“¤ ìˆ˜ ìˆì–´?"
ğŸ“ ë ˆì‹œí”¼ ì¡°ë¦¬ë²•: "ê¹€ì¹˜ì°Œê°œ ë§Œë“œëŠ” ë²•"
ğŸ“‹ ìš”ë¦¬ ì¬ë£Œ í™•ì¸: "ë¶ˆê³ ê¸° ì¬ë£Œê°€ ë­ì•¼?"
ğŸ“Š ì˜ì–‘ì •ë³´ í™•ì¸: "ê³„ë€ë§ì´ ì¹¼ë¡œë¦¬"
ğŸ’¡ ì¡°ë¦¬ íŒ: "íŒŒìŠ¤íƒ€ ë§Œë“¤ ë•Œ íŒ"

í˜„ì¬ {len(self.recipes)}ê°œì˜ ë ˆì‹œí”¼ì™€ {len(self.qa_dataset)}ê°œì˜ QA ë°ì´í„°ë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
í¸í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš”!"""
        
        # ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜
        intent = self.classify_question_intent(clean_input)
        
        # ìœ ì‚¬í•œ QA ì°¾ê¸°
        similar_qa = self.find_similar_qa(clean_input)
        
        if similar_qa and similar_qa[0][1] > 0.7:  # ë†’ì€ ìœ ì‚¬ë„
            return similar_qa[0][0]['answer']
        
        # ì¬ë£Œ ì¶”ì¶œ ë° ê²€ìƒ‰
        ingredients = self.text_processor.extract_ingredients(clean_input)
        if ingredients:
            recipes = self.search_recipes_by_ingredient(ingredients[0])
            if recipes:
                if intent == 'ingredients':
                    return self.format_recipe_response(recipes[0], 'ingredients')
                elif intent == 'steps':
                    return self.format_recipe_response(recipes[0], 'steps')
                elif intent == 'nutrition':
                    return self.format_recipe_response(recipes[0], 'nutrition')
                else:
                    recipe_names = [recipe['name'] for recipe in recipes]
                    return f"{ingredients[0]}ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë“¤ì„ ì¶”ì²œí•´ë“œë¦´ê²Œìš”:\n\n" + "\n".join([f"â€¢ {name}" for name in recipe_names])
        
        # ë ˆì‹œí”¼ ì´ë¦„ ì¶”ì¶œ ë° ê²€ìƒ‰
        recipe_name = self.text_processor.extract_recipe_name(clean_input)
        if recipe_name:
            recipes = self.search_recipes_by_name(recipe_name)
            if recipes:
                if intent == 'ingredients':
                    return self.format_recipe_response(recipes[0], 'ingredients')
                elif intent == 'steps':
                    return self.format_recipe_response(recipes[0], 'steps')
                elif intent == 'nutrition':
                    return self.format_recipe_response(recipes[0], 'nutrition')
                elif intent == 'tips':
                    return self.format_recipe_response(recipes[0], 'tips')
                else:
                    return self.format_recipe_response(recipes[0], 'full')
        
        # ìœ ì‚¬í•œ QAê°€ ìˆë‹¤ë©´ ì‚¬ìš©
        if similar_qa:
            return similar_qa[0][0]['answer']
        
        # ê¸°ë³¸ ì‘ë‹µ
        return f"""ì£„ì†¡í•´ìš”, í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ˜…

í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ:
â€¢ ë ˆì‹œí”¼ ìˆ˜: {len(self.recipes)}ê°œ
â€¢ QA ë°ì´í„°: {len(self.qa_dataset)}ê°œ

ë‹¤ìŒê³¼ ê°™ì´ ì§ˆë¬¸í•´ë³´ì„¸ìš”:
â€¢ "ê°ìë¡œ ë­ ë§Œë“¤ ìˆ˜ ìˆì–´?"
â€¢ "ê¹€ì¹˜ì°Œê°œ ë§Œë“œëŠ” ë²•"
â€¢ "ë¶ˆê³ ê¸° ì¬ë£Œê°€ ë­ì•¼?"
â€¢ "ê³„ë€ë§ì´ ì¹¼ë¡œë¦¬"

ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆì–´ìš”!"""